{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define folders containing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Absolute path\n",
    "HERE = path.abspath('.')\n",
    "\n",
    "#Path to the folder containing the .ms1 files\n",
    "ms1_folder =  path.join(HERE, 'ms1')\n",
    "\n",
    "#Path to the folder containing the chromatograms as .csv files\n",
    "chromatogram_folder = path.join(HERE, 'chromatograms')\n",
    "\n",
    "ms1_files = glob(path.join(ms1_folder, '*.ms1'))\n",
    "\n",
    "chromatograms = glob(path.join(chromatogram_folder, '*.csv'))\n",
    "\n",
    "#File containing the data for the possible possible products (MA, m/z peaks)\n",
    "MA_file = path.join(HERE, 'products_MA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the functions to process MS spectra and chromatograms (the functions are taken from the previous notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_match(ms1file, MAfile):\n",
    "    \n",
    "    '''Take a .ms1 file and filter it extracting the BPIs over a certain threshold and their m/z. Take a MAfile containing the\n",
    "    predicted data for the possible products and match them with the filtered peaks '''\n",
    "\n",
    "    with open(ms1file,'r') as f:\n",
    "        \n",
    "        #read the file as one scan per time\n",
    "        lines = f.read()\n",
    "        lines = lines.split('S')[3:]\n",
    "        scans = [line.split('\\n') for line in lines]\n",
    "        \n",
    "        #for each scan, extract the BPI and its corresponding m/z and retention time\n",
    "        scan_number = []\n",
    "        ret_times = []\n",
    "        bpis = []\n",
    "        m_z = []\n",
    "\n",
    "        for line in lines:\n",
    "            \n",
    "            data = line.split('\\n')\n",
    "            \n",
    "            scan = int(''.join([el for el in data[1] if el.isdigit()]))\n",
    "\n",
    "            scan_number.append(scan)\n",
    "\n",
    "            rtime = float(data[2][8:])\n",
    "            \n",
    "            ret_times.append(rtime)\n",
    "            \n",
    "            bpi = int(data[3][6:])\n",
    "            \n",
    "            bpis.append(bpi)\n",
    "\n",
    "            for count in data[5:-1]:\n",
    "\n",
    "                pairs = count.split()\n",
    "                if int(pairs[1]) == bpi:\n",
    "                    m_z.append(float(pairs[0]))\n",
    "        \n",
    "        scan_number = np.array(scan_number)\n",
    "        ret_times = np.array(ret_times)\n",
    "        bpis = np.array(bpis)\n",
    "        m_z = np.array(m_z)\n",
    "        \n",
    "\n",
    "    #Find maxima and filter those who are less than 1/20 of the max peak\n",
    "    maxs = find_peaks(bpis, height=bpis.max()/20, prominence=bpis.max()/50)[0]\n",
    "    \n",
    "    #Select those peaks and their corresponding data\n",
    "    scan_number = scan_number[maxs]\n",
    "    ret_times = ret_times[maxs]\n",
    "    bpis = bpis[maxs]\n",
    "    m_z = m_z[maxs]\n",
    "    \n",
    "    #create a df containing the data for each peak\n",
    "    data = pd.DataFrame({'mz':m_z, 'BPI': bpis, 'Rtime': ret_times, 'N scan': scan})\n",
    "    \n",
    "    #create a df containing the data for the predicted products\n",
    "    predicted = pd.read_csv(MAfile, encoding='utf-8')\n",
    "\n",
    "    predicted['Match'] = None\n",
    "\n",
    "    predicted['m_z'] = np.nan\n",
    "\n",
    "    predicted['Retention times'] = np.nan\n",
    "\n",
    "    predicted['Base Peaks'] = np.nan\n",
    "\n",
    "    #Now, set a threshold and check if for each row in data (filtered bpi) there is a match with any of\n",
    "    #the predicted masses for the possible compounds\n",
    "\n",
    "    threshold = 0.05\n",
    "\n",
    "    difs = []\n",
    "    \n",
    "    for row in data.itertuples():\n",
    "        \n",
    "        #Set min and max threshold for the monoisotopic mass\n",
    "        min_lim = row[1] - threshold\n",
    "        max_lim = row[1] + threshold\n",
    "        \n",
    "        diff = 10000\n",
    "        \n",
    "        #iterate through each possible product, and if there is a match and the mass difference\n",
    "        #is lower than the previous one, update the difference and overwrite peak data\n",
    "        for molecule in predicted.itertuples():\n",
    "            \n",
    "            if min_lim < molecule[4] < max_lim and abs(molecule[4] - row[1]) < diff:\n",
    "\n",
    "                predicted.at[molecule.Index,'Match'] = True\n",
    "                predicted.at[molecule.Index,'m_z'] = row.mz\n",
    "                predicted.at[molecule.Index,'Retention times'] = row.Rtime\n",
    "                predicted.at[molecule.Index,'Base Peaks'] = row.BPI\n",
    "                \n",
    "                diff = abs(molecule[4] - row[1])\n",
    "    \n",
    "    #Select only the matches\n",
    "    predicted = predicted[predicted.Match == True]\n",
    "\n",
    "    predicted = predicted.infer_objects().sort_values(by='Retention times')\n",
    "\n",
    "    return predicted\n",
    "\n",
    "\n",
    "        \n",
    "def match_chromatogram(chromatogram, filtered):\n",
    "    \n",
    "    '''Open chromatogram as a pandas DF and merge it with the corresponding filtered .ms1 files. It returns a\n",
    "    .csv file containing the merged DF and the relative abundance of the predicted products (calculated just\n",
    "    considering the matched peaks) '''\n",
    "    \n",
    "    chrom = pd.read_csv(chromatogram, encoding = 'utf-8')\n",
    "    \n",
    "    merged = pd.merge_asof(filtered, chrom, left_on='Retention times', right_on='RT [min]', direction='nearest')\n",
    "\n",
    "    merged['Abundance']= (merged['Area']/sum(merged['Area']))*100\n",
    "\n",
    "    return merged\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process all .ms1 files and chromatograms and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, ms1) in enumerate(ms1_files):\n",
    "\n",
    "    filtered = filter_match(ms1, MA_file)\n",
    "\n",
    "    matched = match_chromatogram(chromatograms[i], filtered)\n",
    "\n",
    "    matched.to_csv(path.join(HERE, 'Results', ms1[-7:-4] + '.csv'), encoding='utf-8')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddf727b4b842846146cd0e65866ae7779140f419dbc90c27e95ca4b700c9c8f9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
